{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable\n",
      "0         A\n",
      "1         B\n",
      "2         C\n",
      "3         D\n",
      "4         E\n",
      "5         F\n",
      "6         G\n",
      "7         H\n",
      "8         I\n",
      "9         J\n",
      "10        K\n",
      "11        L\n",
      "12        M\n",
      "13        N\n",
      "14        O\n",
      "15        P\n",
      "16        Q\n",
      "17        R\n",
      "18        S\n",
      "19        T\n",
      "20        U\n",
      "21        V\n",
      "22        W\n",
      "23        X\n",
      "24        Y\n",
      "25        Z\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable\n",
      "0         A\n",
      "1         B\n",
      "2         C\n",
      "3         D\n",
      "4         E\n",
      "5         F\n",
      "6         G\n",
      "7         H\n",
      "8         I\n",
      "9         J\n",
      "10        K\n",
      "11        L\n",
      "12        M\n",
      "13        N\n",
      "14        O\n",
      "15        P\n",
      "16        Q\n",
      "17        R\n",
      "18        S\n",
      "19        T\n",
      "20        U\n",
      "21        V\n",
      "22        W\n",
      "23        X\n",
      "24        Y\n",
      "25        Z\n",
      "  Variable\n",
      "0        A\n",
      "1        B\n",
      "2        C\n",
      "3        D\n",
      "4        E\n",
      "5        F\n",
      "6        G\n",
      "7        H\n",
      "8        I\n",
      "9        J\n",
      "   Variable\n",
      "16        Q\n",
      "17        R\n",
      "18        S\n",
      "19        T\n",
      "20        U\n",
      "21        V\n",
      "22        W\n",
      "23        X\n",
      "24        Y\n",
      "25        Z\n",
      "   Variable\n",
      "6         G\n",
      "22        W\n",
      "25        Z\n",
      "24        Y\n",
      "9         J\n",
      "0         A\n",
      "23        X\n",
      "5         F\n",
      "19        T\n",
      "20        U\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26 entries, 0 to 25\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Variable  26 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 340.0+ bytes\n",
      "None\n",
      "       Variable\n",
      "count        26\n",
      "unique       26\n",
      "top           A\n",
      "freq          1\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "variable = pd.DataFrame({'Variable': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']})   \n",
    "\n",
    "print(variable)\n",
    "\n",
    "print(variable.head(10))\n",
    "print(variable.tail(10))\n",
    "print(variable.sample(10))\n",
    "print(variable.info())\n",
    "print(variable.describe())\n",
    "print(variable.shape)\n",
    "print(variable.columns)\n",
    "print(variable.index)\n",
    "print(variable.dtypes)\n",
    "print(variable.values)\n",
    "print(variable.isnull().sum())\n",
    "print(variable.count())\n",
    "print(variable.nunique())\n",
    "print(variable['Variable'].unique())\n",
    "print(variable.sort_values(['Variable'], ascending=False))\n",
    "print(variable.sort_values(['Variable'], ascending=True))\n",
    "print(variable.sort_values(['region', 'family_members'], ascending=[True, False]))\n",
    "print(variable.sort_values(['region', 'family_members'], ascending=[True, False]).drop_duplicates(subset='region'))\n",
    "print(variable.drop_duplicates(subset='region'))\n",
    "print(variable.drop_duplicates(subset='region').reset_index())\n",
    "\n",
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"]  / homelessness[\"state_pop\"] \n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = high_homelessness.sort_values(['indiv_per_10k'], ascending=False)\n",
    "\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[['state','indiv_per_10k']]\n",
    "\n",
    "# See the result\n",
    "print(result)\n",
    "\n",
    "# Print the head of the sales DataFrame\n",
    "print(sales.head())\n",
    "\n",
    "# Print the info about the sales DataFrame\n",
    "print(sales.info())\n",
    "\n",
    "# Print the mean of weekly_sales\n",
    "print(sales['weekly_sales'].mean())\n",
    "\n",
    "# Print the median of weekly_sales\n",
    "print(sales['weekly_sales'].median())\n",
    "\n",
    "df['column'].agg(function)\n",
    "\n",
    "# Import NumPy and create custom IQR function\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, np.median]))\n",
    "\n",
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales_1_1.sort_values('date')\n",
    "\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1['cum_weekly_sales'] = sales_1_1['weekly_sales'].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1['cum_max_sales'] = sales_1_1['weekly_sales'].cummax()\n",
    "\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])\n",
    "\n",
    "\n",
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates(subset=['store', 'type'])\n",
    "print(store_types.head())\n",
    "\n",
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates(subset=['store', 'department'])\n",
    "print(store_depts.head())\n",
    "\n",
    "# Subset the rows where is_holiday is True and drop duplicate dates\n",
    "holiday_dates = sales[sales['is_holiday'] == True].drop_duplicates(subset='date')\n",
    "\n",
    "# Print date col of holiday_dates\n",
    "print(holiday_dates['date'])\n",
    "\n",
    "\n",
    "# Count the number of stores of each type\n",
    "store_counts = store_types['type'].value_counts()\n",
    "print(store_counts)\n",
    "\n",
    "# Get the proportion of stores of each type\n",
    "store_props = store_types['type'].value_counts(normalize=True)\n",
    "print(store_props)\n",
    "\n",
    "# Count the number of stores for each department and sort\n",
    "dept_counts_sorted = store_depts['department'].value_counts(sort=True)\n",
    "print(dept_counts_sorted)\n",
    "\n",
    "# Get the proportion of stores in each department and sort\n",
    "dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)\n",
    "\n",
    "#print(store_types)\n",
    "\n",
    "dogs.groupby([\"color\", \"breed\"])[[\"weight_kg\", \"height_cm\"]].mean()                   weight_kg  height_cmcolor breed                            Black Labrador            29         59      Poodle              24         43Brown Chow Chow           24         46      Labrador            24         56Gray  Schnauzer           17         49Tan   Chihuahua            2         18White St. Bernard         74         77\n",
    "\n",
    "\n",
    "# Calc total weekly sales\n",
    "sales_all = sales['weekly_sales'].sum()\n",
    "\n",
    "# Subset for type A stores, calc total weekly sales\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type B stores, calc total weekly sales\n",
    "sales_B = sales[sales['type'] == 'B']['weekly_sales'].sum()\n",
    "\n",
    "# Subset for type C stores, calc total weekly sales\n",
    "sales_C = sales[sales['type'] == 'C']['weekly_sales'].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales['weekly_sales'].sum()\n",
    "print(sales_propn_by_type)\n",
    "\n",
    "# From previous step\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Group by type and is_holiday; calc total weekly sales\n",
    "sales_by_type_is_holiday = sales.groupby(['type','is_holiday'])[\"weekly_sales\"].sum()\n",
    "print(sales_by_type_is_holiday)\n",
    "\n",
    "# Import numpy with the alias np\n",
    "import numpy as np\n",
    "\n",
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby('type')['weekly_sales'].agg([min,max,np.mean,np.median])\n",
    "\n",
    "# Print sales_stats\n",
    "print(sales_stats)\n",
    "\n",
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "unemp_fuel_stats = sales.groupby('type')[['unemployment','fuel_price_usd_per_l']].agg([min,max,np.mean,np.median])\n",
    "\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)\n",
    "\n",
    "dogs.pivot_table(values=\"weight_kg\", index=\"color\", aggfunc=np.median)       weight_kgcolor           Black       26.5Brown       24.0Gray        17.0Tan          2.0White       74.0\n",
    "\n",
    "\n",
    "# Import NumPy as np\n",
    "import numpy as np\n",
    "\n",
    "# Pivot for mean and median weekly_sales for each store type\n",
    "mean_med_sales_by_type = sales.pivot_table(values='weekly_sales', aggfunc= [np.mean,np.median], index='type')\n",
    "\n",
    "# Print mean_med_sales_by_type\n",
    "print(mean_med_sales_by_type)\n",
    "\n",
    "# Pivot for mean weekly_sales by store type and holiday \n",
    "mean_sales_by_type_holiday = sales.pivot_table(index='type', columns='is_holiday', values='weekly_sales')\n",
    "\n",
    "# Print mean_sales_by_type_holiday\n",
    "print(mean_sales_by_type_holiday)\n",
    "\n",
    "# Print mean weekly_sales by department and type; fill missing values with 0\n",
    "print(sales.pivot_table(columns='type', index='department', values='weekly_sales',fill_value=0))\n",
    "\n",
    "# Look at temperatures\n",
    "print(temperatures.values)\n",
    "\n",
    "# Set the index of temperatures to city\n",
    "temperatures_ind = temperatures.set_index('city')\n",
    "\n",
    "# Look at temperatures_ind\n",
    "print(temperatures_ind.values)\n",
    "\n",
    "# Reset the temperatures_ind index, keeping its contents\n",
    "print(temperatures_ind.reset_index())\n",
    "\n",
    "# Reset the temperatures_ind index, dropping its contents\n",
    "print(temperatures_ind.reset_index(drop=True))\n",
    "\n",
    "# Make a list of cities to subset on\n",
    "cities = [\"Moscow\", \"Saint Petersburg\"]\n",
    "\n",
    "# Subset temperatures using square brackets\n",
    "print(temperatures[temperatures['city'].isin(cities)])\n",
    "\n",
    "# Subset temperatures_ind using .loc[]\n",
    "print(temperatures_ind.loc[cities])\n",
    "\n",
    "# Sort temperatures_ind by index values\n",
    "print(temperatures_ind.sort_index())\n",
    "\n",
    "# Sort temperatures_ind by index values at the city level\n",
    "print(temperatures_ind.sort_index(level='city'))\n",
    "\n",
    "# Sort temperatures_ind by country then descending city\n",
    "print(temperatures_ind.sort_index(level=['country','city'],ascending=[True,False]))\n",
    "\n",
    "# Sort the index of temperatures_ind\n",
    "temperatures_srt = temperatures_ind.sort_index()\n",
    "\n",
    "# Subset rows from Pakistan to Russia\n",
    "print(temperatures_srt.loc['Pakistan':'Russia'])\n",
    "\n",
    "# Subset rows from Pakistan, Lahore to Russia, Moscow\n",
    "print(temperatures_srt.loc[('Pakistan','Lahore'):('Russia','Moscow')])\n",
    "\n",
    "# Subset rows from India, Hyderabad to Iraq, Baghdad\n",
    "print(temperatures_srt.loc[('India','Hyderabad'):('Iraq','Baghdad')])\n",
    "\n",
    "# Subset columns from date to avg_temp_c\n",
    "print(temperatures_srt.loc[:,'date':'avg_temp_c'])\n",
    "\n",
    "# Subset in both directions at once\n",
    "print(temperatures_srt.loc[('India','Hyderabad'):('Iraq','Baghdad'),'date':'avg_temp_c'])\n",
    "\n",
    "# Get 23rd row, 2nd column (index 22, 1)\n",
    "print(temperatures.iloc[22:23,1:2])\n",
    "\n",
    "# Use slicing to get the first 5 rows\n",
    "print(temperatures[:5])\n",
    "\n",
    "# Use slicing to get columns 3 to 4\n",
    "print(temperatures.iloc[:,2:4])\n",
    "\n",
    "# Use slicing in both directions at once\n",
    "print(temperatures.iloc[:5,2:4])\n",
    "\n",
    "# Add a year column to temperatures\n",
    "temperatures['year']=temperatures['date'].dt.year\n",
    "\n",
    "# Pivot avg_temp_c by country and city vs year\n",
    "temp_by_country_city_vs_year = temperatures.pivot_table(index=['country','city'],values='avg_temp_c',columns='year')\n",
    "\n",
    "# See the result\n",
    "print(temp_by_country_city_vs_year)\n",
    "\n",
    "# Subset for Egypt to India\n",
    "temp_by_country_city_vs_year.loc['Egypt':'India']\n",
    "\n",
    "# Subset for Egypt, Cairo to India, Delhi\n",
    "temp_by_country_city_vs_year.loc[('Egypt','Cairo'):('India','Delhi')]\n",
    "\n",
    "# Subset for Egypt, Cairo to India, Delhi, and 2005 to 2010\n",
    "temp_by_country_city_vs_year.loc[('Egypt','Cairo'):('India','Delhi'),2005:2010]\n",
    "\n",
    "# Get the worldwide mean temp by year\n",
    "mean_temp_by_year = temp_by_country_city_vs_year.mean()\n",
    "\n",
    "# Filter for the year that had the highest mean temp\n",
    "print(mean_temp_by_year[mean_temp_by_year.max() == mean_temp_by_year])\n",
    "\n",
    "# Get the mean temp by city\n",
    "mean_temp_by_city = temp_by_country_city_vs_year.mean('columns')\n",
    "\n",
    "# Filter for the city that had the lowest mean temp\n",
    "print(mean_temp_by_city[mean_temp_by_city.min() == mean_temp_by_city])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
